{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60fd0ea-bc9b-435b-8ab6-4644f9896013",
   "metadata": {},
   "source": [
    "<h1><center>Análisis de Sistemas de Infraestructura <br>\n",
    "    Taller 2: Machine Learning </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a89d3b-d9f5-4288-b319-74ae44226966",
   "metadata": {},
   "source": [
    "<h2> 2. Regresión logística y Redes neuronales.</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054bfbca-2a39-44e5-8bbd-4575bfe040c4",
   "metadata": {},
   "source": [
    " Importar las librerías que usaremos en el taller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555f2b4b-c74d-4ee6-b7f9-b3902cb28adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Parte1Taller2.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elapsed time was 0.0\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.1181009111855882\n",
      "R2 score is 0.6324965086938636\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.1381513927349074\n",
      "R2 score is -1.851552533562546\n",
      "The elapsed time was 0.000995635986328125\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.02049250815658428\n",
      "R2 score is 0.8012519374302236\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.29398717913771466\n",
      "R2 score is 0.00865374750549286\n",
      "The elapsed time was 0.0\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.07052550506097634\n",
      "R2 score is 0.6593396496909949\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.2576336462299111\n",
      "R2 score is 0.16765601655994988\n",
      "The elapsed time was 0.0\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.023024328806914383\n",
      "R2 score is 0.5388682944240104\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.22017894161036186\n",
      "R2 score is 0.03906096948820725\n"
     ]
    }
   ],
   "source": [
    "#Importar las librerías necesarias\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf #Importacion de librerias de trabajo\n",
    "from tensorflow import keras\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import import_ipynb\n",
    "import Parte1Taller2#Libreria de nuestro archivo primera parte del taller, para poder importarla de esta forma ambos archivos tienen que estar en una misma ruta (misma carpeta) \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23486a-f506-4b13-b03d-2eb799f2a002",
   "metadata": {},
   "source": [
    "<h3> Importar los datos </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d57823-cb29-486c-837a-088f9a0d9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos algunos DataFrame con los que trabajamos en la primera parte del taller \n",
    "from Parte1Taller2 import df_GDP, Datos_pilar_infr, lista_nombres_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73b21d-9d13-4f01-b5f5-82709b936a43",
   "metadata": {},
   "source": [
    "<h3>Divida los países en 4 categorías según los cuartiles del GDP. A cada país asigne un número que\n",
    "determine la categoría a la que pertenece (i.e. números del 0 al 3).</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d531b0d4-3266-4b60-91b8-3ec35e5fd864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana de los datos es 0    0.001233\n",
      "dtype: float64\n",
      "Q1 es 0    0.000299\n",
      "Name: 0.25, dtype: float64\n",
      "Q3 0    0.010498\n",
      "Name: 0.75, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "longitud=len(df_GDP) # Numero de paises\n",
    "\n",
    "# Obtenermos Q1, Q2, Q3\n",
    "\n",
    "mediana=df_GDP.median() \n",
    "Q3=df_GDP.quantile(0.75) #Cuartil 3\n",
    "Q1=df_GDP.quantile(0.25) #Cuartil 1\n",
    "\n",
    "df_GDP=df_GDP.sort_values(by=0,ascending=False) #Ordenar \n",
    "\n",
    "print('Q1 es', Q1)\n",
    "print('La mediana de los datos es', mediana)\n",
    "print('Q3 3s', Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "667f2cfb-ede0-45c4-b2c6-6de20464b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos por encima del Q3 - Clasificacion 3\n",
    "\n",
    "cont=(Q3<df_GDP).sum() #Numero de valores por encima del cuartil Q3\n",
    "\n",
    "Cuartil_superior=np.zeros(int(cont))\n",
    "for n in range (int(cont)):\n",
    "    Cuartil_superior[n]=df_GDP.iloc[n]\n",
    "    \n",
    "Cuartil_superior=pd.DataFrame(Cuartil_superior, index=df_GDP[:int(cont)].index)\n",
    "Cuartil_superior['clasificación']=3\n",
    "\n",
    "# Datos entre el Q2 y Q3\n",
    "\n",
    "cont1=(mediana<df_GDP).sum() #Numero de valores entre Q2 y Q3\n",
    "cont1=cont1-cont\n",
    "\n",
    "Cuartil_Q3=np.zeros(int(cont1))\n",
    "for n in range (int(cont1)):\n",
    "    Cuartil_Q3[n]=df_GDP.iloc[n+int(cont)]\n",
    "\n",
    "df_GDP_v=df_GDP[int(cont):]\n",
    "df_GDP_v=df_GDP_v[:int(cont1)]\n",
    "\n",
    "Cuartil_Q3=pd.DataFrame(Cuartil_Q3, index=df_GDP_v.index)\n",
    "Cuartil_Q3['clasificación']=2\n",
    "\n",
    "# Datos entre el Q1 y Q2\n",
    "\n",
    "cont2=(Q1<df_GDP).sum() #Numero de valores entre Q1 y Q2\n",
    "cont2=cont2-cont1-cont\n",
    "\n",
    "Cuartil_Q1=np.zeros(int(cont2))\n",
    "for n in range (int(cont2)):\n",
    "    Cuartil_Q1[n]=df_GDP.iloc[n+int(cont1)+int(cont)]\n",
    "\n",
    "lim=int(cont)+int(cont1)\n",
    "df_GDP_v=df_GDP[lim:]\n",
    "df_GDP_v=df_GDP_v[:int(cont2)]\n",
    "\n",
    "Cuartil_Q1=pd.DataFrame(Cuartil_Q1, index=df_GDP_v.index)\n",
    "Cuartil_Q1['clasificación']=1\n",
    "\n",
    "# Datos por debajo del Q1\n",
    "\n",
    "cont3=(Q1>df_GDP).sum() #Numero de valores por abajo de Q1\n",
    "\n",
    "Cuartil_inferior=np.zeros(int(cont3))\n",
    "for n in range (int(cont3)):\n",
    "    Cuartil_inferior[n]=df_GDP.iloc[n+int(cont1)+int(cont)+int(cont2)]\n",
    "\n",
    "lim=int(cont)+int(cont1)+int(cont2)\n",
    "df_GDP_v=df_GDP[lim:]\n",
    "df_GDP_v=df_GDP_v[:int(cont3)]\n",
    "\n",
    "Cuartil_inferior=pd.DataFrame(Cuartil_inferior, index=df_GDP_v.index)\n",
    "Cuartil_inferior['clasificación']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e377fab0-16fe-4283-8db4-743f5234d38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>clasificacion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>0.667881</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>0.239369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>0.181852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Asia</th>\n",
       "      <td>0.171085</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palau</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marshall Islands</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kiribati</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nauru</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuvalu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       GDP  clasificacion\n",
       "Country Name                             \n",
       "United States     1.000000              3\n",
       "China             0.667881              3\n",
       "Japan             0.239369              3\n",
       "Germany           0.181852              3\n",
       "South Asia        0.171085              3\n",
       "...                    ...            ...\n",
       "Palau             0.000011              0\n",
       "Marshall Islands  0.000008              0\n",
       "Kiribati          0.000006              0\n",
       "Nauru             0.000003              0\n",
       "Tuvalu            0.000000              0\n",
       "\n",
       "[218 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un solo Dataframe con los datos clasificados\n",
    "\n",
    "frames = [Cuartil_superior, Cuartil_Q3, Cuartil_Q1, Cuartil_inferior]\n",
    "datos_GDP_clasificados=pd.concat(frames)\n",
    "datos_GDP_clasificados.columns=['GDP','clasificacion']\n",
    "datos_GDP_clasificados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3dabb-aebe-49c1-80cf-e707e4c9f73b",
   "metadata": {},
   "source": [
    "<h3> Entrene una red neuronal cuya entrada sean los indicadores contenidos en el Pilar de Infraestructura del GCI y que entregue la categoría a la que pertenece el país. <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90128383-fc46-489e-ad5f-56241ca8a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 11) (26, 11) (100,) (26,)\n"
     ]
    }
   ],
   "source": [
    "data=pd.merge(Datos_pilar_infr, datos_GDP_clasificados, on='Country Name', suffixes=('_left', '_right'))\n",
    "\n",
    "X = data.iloc[:,0:11].values\n",
    "Y = data['clasificacion'].values\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaler = min_max_scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaler, Y, test_size = 0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4412467-7c00-4aeb-a3ce-77b12db4e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 11)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1604 (6.27 KB)\n",
      "Trainable params: 1604 (6.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a simple sequential model\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(11,)),\n",
    "        keras.layers.Dense(100, activation='relu', input_shape=(11,)),\n",
    "        keras.layers.Dense(4, activation='softmax'), #4 neuronas de salida porque tenemos 4 clasificaciones posibles\n",
    "      ])\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "\n",
    "model = create_model() #Creacion del modelo de red neuronal\n",
    "\n",
    "# Display the model's architecture\n",
    "\n",
    "model.summary() #Resum del modelo creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56675765-6bc8-4d57-a2bf-2625037d54c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "4/4 [==============================] - 2s 158ms/step - loss: 1.2897 - accuracy: 0.3600 - val_loss: 1.2971 - val_accuracy: 0.2692\n",
      "Epoch 2/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2475 - accuracy: 0.3600 - val_loss: 1.2781 - val_accuracy: 0.2692\n",
      "Epoch 3/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2131 - accuracy: 0.3600 - val_loss: 1.2722 - val_accuracy: 0.2692\n",
      "Epoch 4/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1837 - accuracy: 0.3600 - val_loss: 1.2644 - val_accuracy: 0.3077\n",
      "Epoch 5/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1607 - accuracy: 0.3600 - val_loss: 1.2504 - val_accuracy: 0.3077\n",
      "Epoch 6/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1387 - accuracy: 0.3600 - val_loss: 1.2406 - val_accuracy: 0.3077\n",
      "Epoch 7/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1202 - accuracy: 0.3600 - val_loss: 1.2321 - val_accuracy: 0.3462\n",
      "Epoch 8/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1047 - accuracy: 0.3600 - val_loss: 1.2247 - val_accuracy: 0.3462\n",
      "Epoch 9/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0892 - accuracy: 0.3700 - val_loss: 1.2154 - val_accuracy: 0.3462\n",
      "Epoch 10/70\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0755 - accuracy: 0.3700 - val_loss: 1.2110 - val_accuracy: 0.3462\n",
      "Epoch 11/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0626 - accuracy: 0.3700 - val_loss: 1.2097 - val_accuracy: 0.3462\n",
      "Epoch 12/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0518 - accuracy: 0.3700 - val_loss: 1.2077 - val_accuracy: 0.3462\n",
      "Epoch 13/70\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0410 - accuracy: 0.4000 - val_loss: 1.1991 - val_accuracy: 0.3462\n",
      "Epoch 14/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0311 - accuracy: 0.4100 - val_loss: 1.1959 - val_accuracy: 0.3462\n",
      "Epoch 15/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0209 - accuracy: 0.4400 - val_loss: 1.1944 - val_accuracy: 0.3462\n",
      "Epoch 16/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0088 - accuracy: 0.4700 - val_loss: 1.1923 - val_accuracy: 0.3846\n",
      "Epoch 17/70\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9993 - accuracy: 0.5300 - val_loss: 1.1900 - val_accuracy: 0.3846\n",
      "Epoch 18/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9913 - accuracy: 0.5900 - val_loss: 1.1853 - val_accuracy: 0.5000\n",
      "Epoch 19/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9831 - accuracy: 0.6200 - val_loss: 1.1792 - val_accuracy: 0.5769\n",
      "Epoch 20/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9752 - accuracy: 0.6100 - val_loss: 1.1777 - val_accuracy: 0.5000\n",
      "Epoch 21/70\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9636 - accuracy: 0.6100 - val_loss: 1.1801 - val_accuracy: 0.4231\n",
      "Epoch 22/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9543 - accuracy: 0.5900 - val_loss: 1.1897 - val_accuracy: 0.3846\n",
      "Epoch 23/70\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9456 - accuracy: 0.5600 - val_loss: 1.1953 - val_accuracy: 0.3846\n",
      "Epoch 24/70\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9364 - accuracy: 0.5900 - val_loss: 1.1988 - val_accuracy: 0.4615\n",
      "Epoch 25/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9305 - accuracy: 0.6300 - val_loss: 1.2023 - val_accuracy: 0.5000\n",
      "Epoch 26/70\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9213 - accuracy: 0.6600 - val_loss: 1.1967 - val_accuracy: 0.5000\n",
      "Epoch 27/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9123 - accuracy: 0.6600 - val_loss: 1.1940 - val_accuracy: 0.5000\n",
      "Epoch 28/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9045 - accuracy: 0.6500 - val_loss: 1.1927 - val_accuracy: 0.5000\n",
      "Epoch 29/70\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8967 - accuracy: 0.6300 - val_loss: 1.1897 - val_accuracy: 0.4615\n",
      "Epoch 30/70\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8896 - accuracy: 0.6500 - val_loss: 1.1825 - val_accuracy: 0.4615\n",
      "Epoch 31/70\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8831 - accuracy: 0.6600 - val_loss: 1.1781 - val_accuracy: 0.4615\n",
      "Epoch 32/70\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8764 - accuracy: 0.6300 - val_loss: 1.1758 - val_accuracy: 0.5000\n",
      "Epoch 33/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8696 - accuracy: 0.6500 - val_loss: 1.1728 - val_accuracy: 0.5769\n",
      "Epoch 34/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8620 - accuracy: 0.6700 - val_loss: 1.1619 - val_accuracy: 0.6154\n",
      "Epoch 35/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8545 - accuracy: 0.6700 - val_loss: 1.1497 - val_accuracy: 0.6154\n",
      "Epoch 36/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8476 - accuracy: 0.7000 - val_loss: 1.1480 - val_accuracy: 0.6154\n",
      "Epoch 37/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8409 - accuracy: 0.6900 - val_loss: 1.1501 - val_accuracy: 0.6154\n",
      "Epoch 38/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8347 - accuracy: 0.6900 - val_loss: 1.1520 - val_accuracy: 0.6154\n",
      "Epoch 39/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8305 - accuracy: 0.6900 - val_loss: 1.1574 - val_accuracy: 0.6154\n",
      "Epoch 40/70\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8245 - accuracy: 0.6900 - val_loss: 1.1515 - val_accuracy: 0.6154\n",
      "Epoch 41/70\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8179 - accuracy: 0.6800 - val_loss: 1.1517 - val_accuracy: 0.6154\n",
      "Epoch 42/70\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8143 - accuracy: 0.7000 - val_loss: 1.1595 - val_accuracy: 0.5769\n",
      "Epoch 43/70\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8139 - accuracy: 0.6900 - val_loss: 1.1693 - val_accuracy: 0.6154\n",
      "Epoch 44/70\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8097 - accuracy: 0.7000 - val_loss: 1.1674 - val_accuracy: 0.6154\n",
      "Epoch 45/70\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8042 - accuracy: 0.7000 - val_loss: 1.1621 - val_accuracy: 0.6154\n",
      "Epoch 46/70\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.7981 - accuracy: 0.6900 - val_loss: 1.1572 - val_accuracy: 0.5769\n",
      "Epoch 47/70\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7895 - accuracy: 0.6900 - val_loss: 1.1404 - val_accuracy: 0.6154\n",
      "Epoch 48/70\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7826 - accuracy: 0.7000 - val_loss: 1.1244 - val_accuracy: 0.6154\n",
      "Epoch 49/70\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7758 - accuracy: 0.7500 - val_loss: 1.1107 - val_accuracy: 0.6154\n",
      "Epoch 50/70\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7713 - accuracy: 0.7100 - val_loss: 1.1028 - val_accuracy: 0.6154\n",
      "Epoch 51/70\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7675 - accuracy: 0.7200 - val_loss: 1.0968 - val_accuracy: 0.6154\n",
      "Epoch 52/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7651 - accuracy: 0.7200 - val_loss: 1.0911 - val_accuracy: 0.6154\n",
      "Epoch 53/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7623 - accuracy: 0.7100 - val_loss: 1.0873 - val_accuracy: 0.5769\n",
      "Epoch 54/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7581 - accuracy: 0.7000 - val_loss: 1.0831 - val_accuracy: 0.5769\n",
      "Epoch 55/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7533 - accuracy: 0.7000 - val_loss: 1.0782 - val_accuracy: 0.5769\n",
      "Epoch 56/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7477 - accuracy: 0.7100 - val_loss: 1.0798 - val_accuracy: 0.6154\n",
      "Epoch 57/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7426 - accuracy: 0.7100 - val_loss: 1.0865 - val_accuracy: 0.5769\n",
      "Epoch 58/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7393 - accuracy: 0.7400 - val_loss: 1.0884 - val_accuracy: 0.5769\n",
      "Epoch 59/70\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7384 - accuracy: 0.7100 - val_loss: 1.0949 - val_accuracy: 0.5000\n",
      "Epoch 60/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7356 - accuracy: 0.7100 - val_loss: 1.0954 - val_accuracy: 0.5000\n",
      "Epoch 61/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7301 - accuracy: 0.7100 - val_loss: 1.0877 - val_accuracy: 0.5769\n",
      "Epoch 62/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7240 - accuracy: 0.7400 - val_loss: 1.0821 - val_accuracy: 0.6154\n",
      "Epoch 63/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7198 - accuracy: 0.7300 - val_loss: 1.0769 - val_accuracy: 0.6154\n",
      "Epoch 64/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7168 - accuracy: 0.7000 - val_loss: 1.0651 - val_accuracy: 0.6154\n",
      "Epoch 65/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7145 - accuracy: 0.7100 - val_loss: 1.0573 - val_accuracy: 0.5769\n",
      "Epoch 66/70\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7143 - accuracy: 0.7200 - val_loss: 1.0508 - val_accuracy: 0.5385\n",
      "Epoch 67/70\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7106 - accuracy: 0.7200 - val_loss: 1.0444 - val_accuracy: 0.5769\n",
      "Epoch 68/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7075 - accuracy: 0.7200 - val_loss: 1.0429 - val_accuracy: 0.5769\n",
      "Epoch 69/70\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7042 - accuracy: 0.7200 - val_loss: 1.0418 - val_accuracy: 0.6154\n",
      "Epoch 70/70\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7017 - accuracy: 0.7100 - val_loss: 1.0432 - val_accuracy: 0.6538\n",
      "The elapsed time was 7.579\n"
     ]
    }
   ],
   "source": [
    "t=time.time()\n",
    "model.fit(X_train, \n",
    "          Y_train,  \n",
    "          epochs=70,\n",
    "          validation_data=(X_test,Y_test)); #Entrenamiento del modelo y validacion\n",
    "elapsed=time.time()-t\n",
    "elapsed_r=round(elapsed,3)\n",
    "print('The elapsed time was {}'.format(elapsed_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7828140f-617b-4d81-82a0-e66faadd4bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 1.0432 - accuracy: 0.6538 - 45ms/epoch - 45ms/step\n",
      "\n",
      "Test accuracy: 0.6538461446762085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1, 2, 1, 1, 3, 1, 0, 2, 3, 0, 1, 2, 3, 2, 2, 2, 3, 3, 2,\n",
       "       2, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " _,test_acc= model.evaluate(X_test, Y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01359fd-0c5c-44af-b8c2-3a46034f83b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test) #Prediciones del modelo\n",
    "predictions[5] #Ejemplo de prediccion\n",
    "np.argmax(predictions[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6937c12-4e19-4dcf-b4cc-04d457c577f4",
   "metadata": {},
   "source": [
    "<h3> Entrene una hipótesis logística que cumpla la misma función de la red neuronal del literal anterior. <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1eca93c-9432-4334-82ba-4734e02d203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elapsed time was 0.11352944374084473\n",
      "The model performance for training set\n",
      "--------------------------------------\n",
      "Accuracy of 0.75\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "Accuracy of 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "X_log_regression= data.iloc[:,0:11].values\n",
    "Y_log_regression = data['clasificacion'].values\n",
    "\n",
    "min_max_scaler_reg = preprocessing.MinMaxScaler()\n",
    "X_scaler_log_regression = min_max_scaler.fit_transform(X_log_regression)\n",
    "\n",
    "X_scaler_log_regression=np.append(X_scaler_log_regression,X_scaler_log_regression**2,axis=1) #Se añaden variables cuadradas\n",
    "X_log_regression_train, X_log_regression_test, Y_log_regression_train, Y_log_regression_test = train_test_split(X_scaler_log_regression, Y_log_regression, test_size = 0.2, random_state=1) # se separan train y test set\n",
    "lr = LogisticRegression() #Se genera el modelo logistico\n",
    "t=time.time()\n",
    "lr.fit(X_log_regression_train, Y_log_regression_train) #Se entrena el modelo\n",
    "elapsed=time.time()-t\n",
    "print('The elapsed time was {}'.format(elapsed))\n",
    "y_pred = lr.predict(X_log_regression_train) #Se realiza la prediccion del train set\n",
    "confusion=confusion_matrix(Y_log_regression_train, y_pred)/np.sum(confusion_matrix(Y_log_regression_train, y_pred)) #generacion de la matriz de errores\n",
    "accuracy=np.trace(confusion) #calculo de la exactitud\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('Accuracy of {}'.format(accuracy))\n",
    "y_pred = lr.predict(X_log_regression_test)\n",
    "confusion=confusion_matrix(Y_log_regression_test, y_pred)/np.sum(confusion_matrix(Y_log_regression_test, y_pred))\n",
    "accuracy=np.trace(confusion)\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('Accuracy of {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "184d52a8-34ac-45fa-a773-e145eef636d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1 = lr.predict(X_log_regression_test) #Prediciones del modelo\n",
    "predictions1[1] #Ejemplo de prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e13042e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.75801228534768"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7.579/0.11352944374084473"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175e50d-decd-45a8-87a0-c4bab1d4c8df",
   "metadata": {},
   "source": [
    "<h3> Si solo se aumenta el indicador de calidad en las vías ¿es posible que Colombia cambie de categoría? <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bfc9265-072a-48e6-a75f-875ff824a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "De acuerdo con la red neuronal (predicion) Colombia esta en categoria 3\n",
      "De acuerdo con la clasificacion real por cuartiles Colombia esta en la categoria 3\n"
     ]
    }
   ],
   "source": [
    "X_2=pd.DataFrame(X_scaler,index=data.index)\n",
    "X_2.columns = lista_nombres_ind\n",
    "\n",
    "originales_Col=np.zeros(11)\n",
    "\n",
    "for n in range (0,11):\n",
    "    originales_Col[n]=X_2[lista_nombres_ind[n]]['Colombia']\n",
    "\n",
    "# Numero de fila de Colombia\n",
    "ind=0\n",
    "for i in range(0, len(X_2)):\n",
    "    if X_2['Quality of road infrastructure'].iloc[i]==X_2['Quality of road infrastructure']['Colombia']:\n",
    "        ind=i\n",
    "    \n",
    "valor_calidad_vias_Col=X_2['Quality of road infrastructure']['Colombia']\n",
    "predictions = model.predict(X_2) #Prediciones  \n",
    "categoria_prediccion_Col=np.argmax(predictions[ind])\n",
    "print('De acuerdo con la red neuronal (predicion) Colombia esta en categoria', categoria_prediccion_Col)\n",
    "print('De acuerdo con la clasificacion real por cuartiles Colombia esta en la categoria', datos_GDP_clasificados['clasificacion']['Colombia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5563bae1-665c-4c69-b608-cc173bf96e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2['Quality of road infrastructure'].iloc[ind]=1 #Cambiando este indicador (0 - 1) puede comprobar en esta celda si la categoria varía\n",
    "predictions = model.predict(X_2) #Prediciones \n",
    "predictions[ind] #Predicción de Colombia\n",
    "np.argmax(predictions[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d62c39-bac6-4759-82b7-babd867988a0",
   "metadata": {},
   "source": [
    "### ¿Qué indicador de infraestructura tiene mayor influencia en el GDP de Colombia? –analice la forma en la que cambian las probabilidades entregadas por la red neuronal para cambios marginales en cada indicador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e654a3d1-59c8-46e8-84b9-b2eefba69256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2['Quality of road infrastructure'].iloc[ind]=originales_Col[1] #Regreso a mis datos originales \n",
    "\n",
    "#Asumir que cada indicador aumenta en 15%\n",
    "def aumento_Colombia(indicador):\n",
    "    X_2[indicador].iloc[ind]=X_2[indicador].iloc[ind]*1.15\n",
    "    return(model.predict(X_2)[ind])\n",
    "\n",
    "#Regresar el indicador a su condición original\n",
    "def regreso(indicador,n):\n",
    "    X_2[indicador].iloc[ind]=originales_Col[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "285a7403-28e0-4bf7-9269-c52dd0d2759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.168285</td>\n",
       "      <td>0.326614</td>\n",
       "      <td>0.490533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 0</th>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.163055</td>\n",
       "      <td>0.327555</td>\n",
       "      <td>0.495606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 1</th>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.165502</td>\n",
       "      <td>0.329669</td>\n",
       "      <td>0.490469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 2</th>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.167234</td>\n",
       "      <td>0.327184</td>\n",
       "      <td>0.491069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 3</th>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.163212</td>\n",
       "      <td>0.321638</td>\n",
       "      <td>0.500931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 4</th>\n",
       "      <td>0.011705</td>\n",
       "      <td>0.125419</td>\n",
       "      <td>0.282346</td>\n",
       "      <td>0.580529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 5</th>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.177279</td>\n",
       "      <td>0.327703</td>\n",
       "      <td>0.481010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 6</th>\n",
       "      <td>0.012330</td>\n",
       "      <td>0.140882</td>\n",
       "      <td>0.297547</td>\n",
       "      <td>0.549241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 7</th>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.175204</td>\n",
       "      <td>0.340523</td>\n",
       "      <td>0.470380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 8</th>\n",
       "      <td>0.014653</td>\n",
       "      <td>0.189468</td>\n",
       "      <td>0.340748</td>\n",
       "      <td>0.455131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 9</th>\n",
       "      <td>0.014655</td>\n",
       "      <td>0.178601</td>\n",
       "      <td>0.342882</td>\n",
       "      <td>0.463862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aumentando indicador 10</th>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.162008</td>\n",
       "      <td>0.329924</td>\n",
       "      <td>0.493684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0         1         2         3\n",
       "Normal                   0.014567  0.168285  0.326614  0.490533\n",
       "Aumentando indicador 0   0.013784  0.163055  0.327555  0.495606\n",
       "Aumentando indicador 1   0.014360  0.165502  0.329669  0.490469\n",
       "Aumentando indicador 2   0.014513  0.167234  0.327184  0.491069\n",
       "Aumentando indicador 3   0.014219  0.163212  0.321638  0.500931\n",
       "Aumentando indicador 4   0.011705  0.125419  0.282346  0.580529\n",
       "Aumentando indicador 5   0.014007  0.177279  0.327703  0.481010\n",
       "Aumentando indicador 6   0.012330  0.140882  0.297547  0.549241\n",
       "Aumentando indicador 7   0.013893  0.175204  0.340523  0.470380\n",
       "Aumentando indicador 8   0.014653  0.189468  0.340748  0.455131\n",
       "Aumentando indicador 9   0.014655  0.178601  0.342882  0.463862\n",
       "Aumentando indicador 10  0.014385  0.162008  0.329924  0.493684"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_aum={}\n",
    "\n",
    "dataset_aum['Normal']=model.predict(X_2)[ind] # Sin aumentar los valores de los indicadores como son las probabilidades\n",
    "\n",
    "for i in range(0,len(lista_nombres_ind)):\n",
    "    dataset_aum['Aumentando indicador %d' %i]=aumento_Colombia(lista_nombres_ind[i])\n",
    "    regreso(lista_nombres_ind[i],i)\n",
    "\n",
    "pd.DataFrame.from_dict(dataset_aum, orient='index') # Note que las columnas representan probabilidades (probabilidad de que el modelo clasifique 0, 1, 2 o 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be680ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
